{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import einops\n",
    "\n",
    "from keras.layers import Input, Dense, concatenate, Embedding, ReLU, Dropout, Bidirectional, GRU, Add, Concatenate\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "UNITS = 256\n",
    "\n",
    "BUFFER_SIZE = 120\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "max_name_features = 5000\n",
    "max_name_len = 4\n",
    "\n",
    "max_ingredient_features = 2000\n",
    "max_ingredient_len = 4\n",
    "\n",
    "max_step_features = 10000\n",
    "max_step_len = 400"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = os.path.join('data', 'choc_recipes.txt')\n",
    "# Using readlines()\n",
    "file1 = open(text_path, 'r')\n",
    "Lines = file1.readlines()\n",
    "\n",
    "names = []\n",
    "ingredients = []\n",
    "steps = []\n",
    "\n",
    "count = 0\n",
    "# Strips the newline character\n",
    "for line in Lines:\n",
    "    pieces = line.split('\\t')\n",
    "    names.append(pieces[0])\n",
    "    ingredients.append(pieces[1])\n",
    "    steps.append(pieces[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_list_list = []\n",
    "for i_string in ingredients:\n",
    "    i = i_string.replace(', ', '*')\n",
    "    i = i.replace(' ', '_')\n",
    "    i = i.replace('*', ', ')\n",
    "\n",
    "    ingredients_list_list.append(i)\n",
    "\n",
    "ingredients = ingredients_list_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name count: 7404\n",
      "Ingredient count: 7404\n",
      "Step count: 7404\n"
     ]
    }
   ],
   "source": [
    "print(f'Name count: {len(names)}')\n",
    "print(f'Ingredient count: {len(ingredients)}')\n",
    "print(f'Step count: {len(steps)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tensor Flow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(names)\n",
    "ingredients = np.array(ingredients)\n",
    "steps = np.array(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(names)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "is_train = np.random.uniform(size=(len(names),)) < 0.8\n",
    "\n",
    "# train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\"names\": names[is_train], \"ingredients\": ingredients[is_train]}, steps[is_train]))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(({\"names\": names[~is_train], \"ingredients\": ingredients[~is_train]}, steps[~is_train]))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Text Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_vectorizer = tf.keras.layers.TextVectorization(\n",
    " max_tokens=max_step_features,\n",
    " output_mode='int',\n",
    " output_sequence_length=max_step_len)\n",
    "\n",
    "#train_raw.map(lambda context, target: context)\n",
    "step_vectorizer.adapt(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'step', 'and', 'the', 'in', 'a', 'to', 'until', 'with']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_vectorizer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_vectorizer = tf.keras.layers.TextVectorization(\n",
    " max_tokens=max_ingredient_features,\n",
    " output_mode='int',\n",
    " output_sequence_length=max_ingredient_len)\n",
    "\n",
    "#train_raw.map(lambda context, target: context)\n",
    "\n",
    "ingredient_vectorizer.adapt(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'butter',\n",
       " 'sugar',\n",
       " 'salt',\n",
       " 'eggs',\n",
       " 'vanilla',\n",
       " 'bakingsoda',\n",
       " 'vanillaextract',\n",
       " 'flour']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_vectorizer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_vectorizer = tf.keras.layers.TextVectorization(\n",
    " max_tokens=max_name_features,\n",
    " output_mode='int',\n",
    " output_sequence_length=max_name_len)\n",
    "\n",
    "#train_raw.map(lambda context, target: context)\n",
    "name_vectorizer.adapt(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'chocolate',\n",
       " 'cake',\n",
       " 'cookies',\n",
       " 'chip',\n",
       " 's',\n",
       " 'brownies',\n",
       " 'fudge',\n",
       " 'butter']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_vectorizer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(inputs, outputs):\n",
    "\n",
    "  names = inputs['names']\n",
    "  ingredients = inputs['ingredients']\n",
    "\n",
    "  name_context = name_vectorizer(names)\n",
    "  ingredient_context = ingredient_vectorizer(ingredients)\n",
    "  context = {'names': name_context, 'ingredients': ingredient_context}\n",
    "\n",
    "  target = step_vectorizer(outputs)\n",
    "  targ_in = target[:,:-1]\n",
    "  targ_out = target[:,1:]\n",
    "  return (context, targ_in), targ_out\n",
    "\n",
    "\n",
    "train_ds = train_dataset.map(process_text, tf.data.AUTOTUNE)\n",
    "test_ds = test_dataset.map(process_text, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 975   33 1876    7]\n",
      "[2 3 6 5]\n",
      "\n",
      "[ 54  30   7  68  77   2 128 304 217 190]\n",
      "[ 30   7  68  77   2 128 304 217 190  28]\n"
     ]
    }
   ],
   "source": [
    "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
    "  \n",
    "  name_tok = ex_context_tok['names']\n",
    "  ingredient_tok = ex_context_tok['ingredients']\n",
    "  print(name_tok[0, :10].numpy()) \n",
    "  print(ingredient_tok[0, :10].numpy()) \n",
    "  print()\n",
    "\n",
    "  print(ex_tar_in[0, :10].numpy()) \n",
    "  print(ex_tar_out[0, :10].numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, name_processor, ingredient_processor, units):\n",
    "    super(Encoder, self).__init__()\n",
    "    \n",
    "    self.name_processor = name_processor\n",
    "    self.ingredient_processor = ingredient_processor\n",
    "\n",
    "    self.name_vocab_size = name_processor.vocabulary_size()\n",
    "    self.ingredient_vocab_size = ingredient_processor.vocabulary_size()\n",
    "    \n",
    "    self.units = units\n",
    "\n",
    "    # The embedding layer converts tokens to vectors\n",
    "    self.name_embedding = tf.keras.layers.Embedding(self.name_vocab_size, units, mask_zero=True)\n",
    "    self.ingredient_embedding = tf.keras.layers.Embedding(self.ingredient_vocab_size, units, mask_zero=True)\n",
    "\n",
    "    self.concat = Concatenate(axis=-1)\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding((self.name_vocab_size + self.ingredient_vocab_size), units, mask_zero=True)\n",
    "    #self.embedding = tf.keras.layers.Embedding(self.name_vocab_size, units, mask_zero=True)\n",
    "\n",
    "    # The RNN layer processes those vectors sequentially.\n",
    "    self.rnn = tf.keras.layers.Bidirectional(\n",
    "        merge_mode='sum',\n",
    "        layer=tf.keras.layers.GRU(units,\n",
    "                            # Return the sequence and state\n",
    "                            return_sequences=True,\n",
    "                            recurrent_initializer='glorot_uniform'))\n",
    "\n",
    "  def call(self, x):\n",
    "\n",
    "\n",
    "    names = x['names']\n",
    "    ingredients = x['ingredients']\n",
    "\n",
    "    #shape_checker = ShapeChecker()\n",
    "    #shape_checker(x, 'batch s')\n",
    "\n",
    "    # 2. The embedding layer looks up the embedding vector for each token.\n",
    "    x1 = self.name_embedding(names)\n",
    "    print(f'Dimensions of x1: {x1.shape}')\n",
    "    x2 = self.ingredient_embedding(ingredients)\n",
    "    print(f'Dimensions of x2: {x2.shape}')\n",
    "    x = self.concat([x1, x2])\n",
    "    print(f'Dimensions of x after concat: {x.shape}')\n",
    "\n",
    "\n",
    "    #print(f'Dimensions of x after concat: {x.shape}')\n",
    "    #x = x1\n",
    "    #x = self.embedding(x)\n",
    "\n",
    "    #shape_checker(x, 'batch s units')\n",
    "    \n",
    "   \n",
    "   \n",
    "    # 3. The GRU processes the sequence of embeddings.\n",
    "    x = self.rnn(x)\n",
    "    print(f'Dimensions of x after rnn: {x.shape}')\n",
    "    #shape_checker(x, 'batch s units')\n",
    "  \n",
    "    # 4. Returns the new sequence of embeddings.\n",
    "    return x\n",
    "\n",
    "  def convert_input(self, ingredients, names):\n",
    "\n",
    "    names = self.name_processor(names)#.to_tensor()\n",
    "    print(f'Name Tokens: {names}')\n",
    "    \n",
    "    ingredients = self.ingredient_processor(ingredients)#.to_tensor()\n",
    "    print(f'Ingredients Tokens: {ingredients}')\n",
    "    x = {\"names\": names, \"ingredients\": ingredients}\n",
    "    context = self(x)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of x1: (64, 4, 256)\n",
      "Dimensions of x2: (64, 4, 256)\n",
      "Dimensions of x after concat: (64, 4, 512)\n",
      "Dimensions of x after rnn: (64, 4, 256)\n",
      "Encoder output, shape (batch, s, units): (64, 4, 256)\n"
     ]
    }
   ],
   "source": [
    "# Encode the input sequence.\n",
    "encoder = Encoder(name_vectorizer, ingredient_vectorizer, UNITS)\n",
    "ex_context = encoder(ex_context_tok)\n",
    "\n",
    "#print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
    "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Tokens: [[2 7 0 0]]\n",
      "Ingredients Tokens: [[3 4 5 6]]\n",
      "Dimensions of x1: (1, 4, 256)\n",
      "Dimensions of x2: (1, 4, 256)\n",
      "Dimensions of x after concat: (1, 4, 512)\n",
      "Dimensions of x after rnn: (1, 4, 256)\n",
      "tf.Tensor(\n",
      "[[[-0.01905754 -0.01716275 -0.00262569 ...  0.01229564  0.01274323\n",
      "   -0.01800387]\n",
      "  [-0.02524667  0.01264304  0.00223324 ... -0.00802431  0.02874554\n",
      "   -0.01396075]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]], shape=(1, 4, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = encoder.convert_input(['sugar, salt, eggs, vanilla'], ['chocolate brownies'])\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n",
    "\n",
    "  def call(self, x, context):\n",
    "    #shape_checker = ShapeChecker()\n",
    "\n",
    "    #shape_checker(x, 'batch t units')\n",
    "    #shape_checker(context, 'batch s units')\n",
    "\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    #shape_checker(x, 'batch t units')\n",
    "    #shape_checker(attn_scores, 'batch heads t s')\n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
    "    #shape_checker(attn_scores, 'batch t s')\n",
    "    self.last_attention_weights = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context sequence, shape (batch, s, units): (64, 4, 256)\n",
      "Target sequence, shape (batch, t, units): (64, 399, 256)\n",
      "Attention result, shape (batch, t, units): (64, 399, 256)\n",
      "Attention weights, shape (batch, t, s):    (64, 399, 4)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = CrossAttention(UNITS)\n",
    "\n",
    "# Attend to the encoded tokens\n",
    "embed = tf.keras.layers.Embedding(step_vectorizer.vocabulary_size(),\n",
    "                                  output_dim=UNITS, mask_zero=True)\n",
    "ex_tar_embed = embed(ex_tar_in)\n",
    "\n",
    "result = attention_layer(ex_tar_embed, ex_context)\n",
    "\n",
    "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
    "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
    "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
    "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.0000001 , 1.        , 0.99999994,\n",
       "       1.0000001 , 1.0000001 , 1.0000001 , 1.0000001 , 1.        ,\n",
       "       0.99999994, 1.        , 1.0000001 , 0.9999999 , 1.        ,\n",
       "       1.        , 1.        , 0.99999994, 1.        , 1.0000001 ,\n",
       "       1.        , 0.99999994, 1.        , 1.0000001 , 0.9999999 ,\n",
       "       1.        , 0.99999994, 1.        , 1.        , 0.99999994,\n",
       "       1.0000001 , 1.0000001 , 1.        , 1.        , 1.        ,\n",
       "       0.99999994, 1.        , 0.99999994, 1.0000001 , 1.        ,\n",
       "       1.        , 1.0000001 , 1.        , 1.        , 1.        ,\n",
       "       1.0000001 , 1.        , 0.99999994, 0.99999994, 1.        ,\n",
       "       1.0000001 , 1.0000001 , 1.        , 1.        , 0.9999999 ,\n",
       "       1.        , 1.        , 1.0000001 , 1.        , 1.0000001 ,\n",
       "       1.        , 0.9999999 , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.99999994, 0.99999994, 1.        ,\n",
       "       0.99999994, 1.        , 1.0000001 , 1.        , 1.0000001 ,\n",
       "       1.0000001 , 1.        , 1.        , 1.0000001 , 1.        ,\n",
       "       1.        , 0.99999994, 1.0000001 , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.99999994, 1.        ,\n",
       "       1.        , 1.        , 1.0000001 , 1.        , 1.        ,\n",
       "       1.        , 1.0000001 , 1.0000001 , 1.        , 1.0000001 ,\n",
       "       1.0000001 , 1.        , 1.        , 1.        , 1.0000001 ,\n",
       "       0.99999994, 1.        , 1.        , 0.99999994, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        ], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  @classmethod\n",
    "  def add_method(cls, fun):\n",
    "    setattr(cls, fun.__name__, fun)\n",
    "    return fun\n",
    "\n",
    "  def __init__(self, text_processor, units):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.text_processor = text_processor\n",
    "    self.vocab_size = text_processor.vocabulary_size()\n",
    "    self.word_to_id = tf.keras.layers.StringLookup(\n",
    "        vocabulary=text_processor.get_vocabulary(),\n",
    "        mask_token='', oov_token='[UNK]')\n",
    "    self.id_to_word = tf.keras.layers.StringLookup(\n",
    "        vocabulary=text_processor.get_vocabulary(),\n",
    "        mask_token='', oov_token='[UNK]',\n",
    "        invert=True)\n",
    "    self.start_token = self.word_to_id('[START]')\n",
    "    self.end_token = self.word_to_id('[END]')\n",
    "\n",
    "    self.units = units\n",
    "\n",
    "\n",
    "    # 1. The embedding layer converts token IDs to vectors\n",
    "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
    "                                               units, mask_zero=True)\n",
    "\n",
    "    # 2. The RNN keeps track of what's been generated so far.\n",
    "    self.rnn = tf.keras.layers.GRU(units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    # 3. The RNN output will be the query for the attention layer.\n",
    "    self.attention = CrossAttention(units)\n",
    "\n",
    "    # 4. This fully connected layer produces the logits for each\n",
    "    # output token.\n",
    "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def call(self,\n",
    "         context, x,\n",
    "         state=None,\n",
    "         return_state=False):  \n",
    "  #shape_checker = ShapeChecker()\n",
    "  #shape_checker(x, 'batch t')\n",
    "  #shape_checker(context, 'batch s units')\n",
    "\n",
    "  # 1. Lookup the embeddings\n",
    "  x = self.embedding(x)\n",
    "  #shape_checker(x, 'batch t units')\n",
    "\n",
    "  # 2. Process the target sequence.\n",
    "  x, state = self.rnn(x, initial_state=state)\n",
    "  #shape_checker(x, 'batch t units')\n",
    "\n",
    "  # 3. Use the RNN output as the query for the attention over the context.\n",
    "  x = self.attention(x, context)\n",
    "  self.last_attention_weights = self.attention.last_attention_weights\n",
    "  #shape_checker(x, 'batch t units')\n",
    "  #shape_checker(self.last_attention_weights, 'batch t s')\n",
    "\n",
    "  # Step 4. Generate logit predictions for the next token.\n",
    "  logits = self.output_layer(x)\n",
    "  #shape_checker(logits, 'batch t target_vocab_size')\n",
    "\n",
    "  if return_state:\n",
    "    return logits, state\n",
    "  else:\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(step_vectorizer, UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder output shape: (batch, s, units) (64, 4, 256)\n",
      "input target tokens shape: (batch, t) (64, 399)\n",
      "logits shape shape: (batch, target_vocabulary_size) (64, 399, 8257)\n"
     ]
    }
   ],
   "source": [
    "logits = decoder(ex_context, ex_tar_in)\n",
    "\n",
    "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
    "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
    "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def get_initial_state(self, context):\n",
    "  batch_size = tf.shape(context)[0]\n",
    "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "  embedded = self.embedding(start_tokens)\n",
    "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def tokens_to_text(self, tokens):\n",
    "  words = self.id_to_word(tokens)\n",
    "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
    "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
    "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
    "  logits, state = self(\n",
    "    context, next_token,\n",
    "    state = state,\n",
    "    return_state=True) \n",
    "\n",
    "  if temperature == 0.0:\n",
    "    next_token = tf.argmax(logits, axis=-1)\n",
    "  else:\n",
    "    logits = logits[:, -1, :]/temperature\n",
    "    next_token = tf.random.categorical(logits, num_samples=1)\n",
    "\n",
    "  # If a sequence produces an `end_token`, set it `done`\n",
    "  done = done | (next_token == self.end_token)\n",
    "  # Once a sequence is done it only produces 0-padding.\n",
    "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
    "\n",
    "  return next_token, done, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'toss dropfuls poke chocoalte cigar extinguished mollases decided length timed',\n",
       "       b'having donuts microwaveble child ever preferably fluted fahrenheit between mushroom',\n",
       "       b'shortcakes dietary out genatin liqeuer roasters wide intense youll exchanges'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the loop variables.\n",
    "next_token, done, state = decoder.get_initial_state(ex_context)\n",
    "tokens = []\n",
    "\n",
    "for n in range(10):\n",
    "  # Run one step.\n",
    "  next_token, done, state = decoder.get_next_token(\n",
    "      ex_context, next_token, done, state, temperature=1.0)\n",
    "  # Add the token to the output.\n",
    "  tokens.append(next_token)\n",
    "\n",
    "# Stack all the tokens together.\n",
    "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
    "\n",
    "# Convert the tokens back to a a string\n",
    "result = decoder.tokens_to_text(tokens)\n",
    "result[:3].numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.keras.Model):\n",
    "  @classmethod\n",
    "  def add_method(cls, fun):\n",
    "    setattr(cls, fun.__name__, fun)\n",
    "    return fun\n",
    "\n",
    "  def __init__(self, units,\n",
    "               name_vectorizer,\n",
    "               ingredient_vectorizer,\n",
    "               step_vectorizer):\n",
    "    super().__init__()\n",
    "    # Build the encoder and decoder\n",
    "    encoder = Encoder(name_vectorizer, ingredient_vectorizer, units)\n",
    "    decoder = Decoder(step_vectorizer, units)\n",
    "\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "\n",
    "  def call(self, inputs):\n",
    "    context, x = inputs\n",
    "    context = self.encoder(context)\n",
    "    logits = self.decoder(context, x)\n",
    "\n",
    "    #TODO(b/250038731): remove this\n",
    "    try:\n",
    "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of x1: (64, 4, 256)\n",
      "Dimensions of x2: (64, 4, 256)\n",
      "Dimensions of x after concat: (64, 4, 512)\n",
      "Dimensions of x after rnn: (64, 4, 256)\n",
      "Target tokens, shape: (batch, t) (64, 399)\n",
      "logits, shape: (batch, t, target_vocabulary_size) (64, 399, 8257)\n"
     ]
    }
   ],
   "source": [
    "model = Translator(UNITS, name_vectorizer, ingredient_vectorizer, step_vectorizer)\n",
    "\n",
    "logits = model((ex_context_tok, ex_tar_in))\n",
    "\n",
    "#print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
    "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
    "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_acc(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
    "\n",
    "    match = tf.cast(y_true == y_pred, tf.float32)\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=masked_loss, \n",
    "              metrics=[masked_acc, masked_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'expected_loss': 9.018817, 'expected_acc': 0.00012110936175366356}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 1.0 * step_vectorizer.vocabulary_size()\n",
    "\n",
    "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
    " \"expected_acc\": 1/vocab_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "20/20 [==============================] - 77s 3s/step - loss: 9.0196 - masked_acc: 7.3931e-05 - masked_loss: 9.0196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 9.019614219665527,\n",
       " 'masked_acc': 7.393107807729393e-05,\n",
       " 'masked_loss': 9.019614219665527}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds, steps=20, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "100/100 [==============================] - 613s 6s/step - loss: 5.3349 - masked_acc: 0.1496 - masked_loss: 5.3349 - val_loss: 3.8811 - val_masked_acc: 0.2896 - val_masked_loss: 3.8811\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds.repeat(), \n",
    "    epochs=1,\n",
    "    steps_per_epoch = 100,\n",
    "    validation_data=test_ds,\n",
    "    validation_steps = 20,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rezepte generieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Translator.add_method\n",
    "def translate(self, ingredients, names, *, max_length=50, temperature=0.0):\n",
    "  context = self.encoder.convert_input(ingredients, names)\n",
    "  batch_size = tf.shape(names)[0]\n",
    "  \n",
    "  # Setup the loop inputs\n",
    "  tokens = []\n",
    "  attention_weights = []\n",
    "  next_token, done, state = self.decoder.get_initial_state(context)\n",
    "\n",
    "  for _ in range(max_length):\n",
    "    # Generate the next token\n",
    "    next_token, done, state = self.decoder.get_next_token(\n",
    "        context, next_token, done,  state, temperature)\n",
    "\n",
    "    # Collect the generated tokens\n",
    "    tokens.append(next_token)\n",
    "    attention_weights.append(self.decoder.last_attention_weights)\n",
    "\n",
    "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
    "      break\n",
    "\n",
    "  # Stack the lists of tokens and attention weights.\n",
    "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
    "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
    "\n",
    "  result = self.decoder.tokens_to_text(tokens)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Tokens: [[2 7 0 0]]\n",
      "Ingredients Tokens: [[3 4 5 6]]\n",
      "Dimensions of x1: (1, 4, 256)\n",
      "Dimensions of x2: (1, 4, 256)\n",
      "Dimensions of x after concat: (1, 4, 512)\n",
      "Dimensions of x after rnn: (1, 4, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'to cool step add the chocolate chips and vanilla step add the chocolate chips and vanilla step add the chocolate chips and vanilla step add the chocolate chips and vanilla step add the chocolate chips and vanilla step add the chocolate chips and vanilla step add the chocolate chips and'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.translate(['sugar, salt, eggs, vanilla'], ['chocolate brownies'])\n",
    "result[0].numpy().decode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Tokens: Tensor(\"text_vectorization_5/RaggedToTensor/RaggedTensorToTensor:0\", shape=(None, 4), dtype=int64)\n",
      "Ingredients Tokens: Tensor(\"text_vectorization_4/RaggedToTensor/RaggedTensorToTensor:0\", shape=(None, 4), dtype=int64)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.embedding.Embedding object at 0x0000017CB80637C0>, because it is not built.\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, embedding_14_layer_call_fn, embedding_14_layer_call_and_return_conditional_losses, embedding_15_layer_call_fn, embedding_15_layer_call_and_return_conditional_losses while saving (showing 5 of 37). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translator\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translator\\assets\n"
     ]
    }
   ],
   "source": [
    "class Export(tf.Module):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None]), tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
    "  def translate(self, ingredients, names):\n",
    "    return self.model.translate(ingredients, names)\n",
    "\n",
    "export = Export(model)\n",
    "\n",
    "tf.saved_model.save(export, 'translator', signatures={'serving_default': export.translate})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "700212c39ba4d9c4ad4a0eeefea16618b4c85aca31676250ae9aeb57c9b998d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
